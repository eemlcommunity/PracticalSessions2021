# Materials for the Generative (VAE) Tutorial  at EEML 2021

**Authors**: David Nagy (slides) and David Szepesvari (colabs)

**Description**: This tutorial contains a conceptual introduction to variational autoencoders from a probabilistic inference perspective, shows how to build a basic MLP based VAE in JAX trained and train it on Fashion MNIST. The code explores the latent representation reconstructions and posterior collapse. Then it introduces beta-VAEs and the effect of the beta term on reconstructions, along with the interpretation of these results based on the information bottleneck view from Alemi et al. 2017. The second part contains a short discussion to disentangled representation learning with beta-VAE and a demo on the dSprites dataset.

Designed for education purposes. Please do not distribute without permission. Write at contact@eeml.eu if you have any question.

You are welcome to reuse this material in other courses or schools, but please reach out to contact@eeml.eu if you plan to do so. We would appreciate it if you could acknowledge that the materials come from EEML2021 and give credits to the authors. Also please keep a link in your materials to the original repo, in case updates occur.
